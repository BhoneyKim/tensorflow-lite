{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "helmet_classification_for_tinyMLproject_part1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-vbg-RZNWk9a",
        "OKEWWrOJZ7mW",
        "px_BlwjVZ_Y1",
        "I9hFqjeBmN5N"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxbyIP98UOoz",
        "colab_type": "text"
      },
      "source": [
        "# Helmet Classification For TinyML Project\n",
        "\n",
        "> 이 notebook 은 open source 컨트리뷰톤 2020 - tinyML (Tensorflow Lite Project) Mobility Team 의 오픈소스 프로젝트를 위해 만들어졌습니다. \n",
        "\n",
        "- 모빌리티 팀 (멘토 맹윤호)\n",
        "- 최예진(팀장), 이민우, 전수민, 이장후, 이경환, 조승현\n",
        "- **.ipynb 제작 - 이장후. 2020/08/25**\n",
        "- **.ipynb 수정자 -**\n",
        "\n",
        "<br>\n",
        "\n",
        "- Target Github Repository : [TinyML : Tensorflow lite for microcontroller](https://github.com/yunho0130/tensorflow-lite)\n",
        "- Team Github Repository : [TinyML-Mobility](https://github.com/orgs/tinyml-mobility/teams)\n",
        "\n",
        "<br>\n",
        "\n",
        "## Before We Start\n",
        "- 런타임 -> GPU 로 변경 하셨나요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yC8JXqNghoE",
        "colab_type": "text"
      },
      "source": [
        "# Google Drive\n",
        "\n",
        "- 학습을 시키기 전 데이터가 있는 google Drive 와 연동을 해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZfIohGzavab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a240c2-b673-4e7f-b56f-8ff39731c610"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRqsMIdWgm6A",
        "colab_type": "text"
      },
      "source": [
        "## Include Library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3kyAsKGbKfZ",
        "colab_type": "text"
      },
      "source": [
        "- 이 노트북의 소스코드는 tensorflow 2.0 이상과 호환되지 않습니다.\n",
        "- Google colab 에서는 %tensorflow_version 을 통해, 원하는 버전의 tensorflow 를 쉽게 불러올 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcV5KCk6a5Ey",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bdb149-0584-4736-f6d4-f7fde686dd35"
      },
      "source": [
        "try:\n",
        "  # This %tensorflow_version magic only works in Colab.\n",
        "  %tensorflow_version 1.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# For your non-Colab code, be sure you have tensorflow==1.15\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bD2Q4nwnbGmw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae340a7d-c5da-488c-b1dc-07b6e5c0b920"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.15.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vbg-RZNWk9a",
        "colab_type": "text"
      },
      "source": [
        "## Serve Data\n",
        "- 헬멧 미착용 데이터셋(1/2) : https://drive.google.com/file/d/1lRm0RZ3uP6b3kBDxsIN4I3PfBuq_1GJa/view?usp=sharing\n",
        "- 헬멧 미착용 데이터셋(2/2) : https://drive.google.com/file/d/1CQbmFnHeBkuTRhXQofu0NqZS30Ip-20R/view?usp=sharing\n",
        "- 헬멧 착용 데이터셋(1/1) : https://drive.google.com/file/d/1WYZV_UTPvjv16Z57uMm_kBSWAYJoI3jk/view?usp=sharing\n",
        "- 위 데이터들을 모두 자신의 구글 드라이브에 올려 둡시다.\n",
        "- 구글 드라이브에게 '바탕화면' 같은 존재는 ```/content/gdrive/\"My Drive\"/``` 입니다.\n",
        "- 저의 경우 위 압축 파일들을 ```/content/gdrive/\"My Drive\"/data/``` 에 넣어 두겠습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "### Zip 압축 풀기\n",
        "- linux 에서 zip 파일의 압축을 풀기 위해서는, unzip 명령을 사용합니다. Google Colab 에서는, ! 를 이용해서 리눅스 명령어를 호출할 수 있습니다.\n",
        "- 이때, 리눅스 명령이 수행되는 위치는, 현재 위치입니다. 현재 위치는 !ls 를 통해 조회할 수 있습니다.\n",
        "- %cd 를 통해, 현재 위치를 이동할 수 있습니다.\n",
        "\n",
        "<br>\n",
        "\n",
        "현재 위치를 조회합니다. <br>\n",
        "```!ls```\n",
        "\n",
        "<br>\n",
        "\n",
        "압축파일이 있는 해당 위치로 이동합니다. <br>\n",
        "```%cd /content/gdrive/\"My Drive\"/data/```\n",
        "\n",
        "<br>\n",
        "\n",
        "압축을 해제합니다. <br>\n",
        "```!unzip <파일명>.zip -d <압축을 풀 폴더>```\n",
        "\n",
        "<br>\n",
        "\n",
        "약간의 시간이 소요됩니다. <br>\n",
        "\n",
        "<br>\n",
        "\n",
        "여담 <br>\n",
        "> 프로젝트를 진행하다가, ls 와 cd 모두 linux 명령인데 왜 cd 는 % 를 사용하고 ls 는 ! 를 사용하는지 궁금할 수 있습니다. 정확히 말하면, % 는 google colab 에서 특정한 목적을 가지고 제공되는 기능으로, magic 이라고 합니다. 반면 ! 는 순수 linux 명령어입니다. !cd 를 이용해서 경로를 이동할 수 있으나, 그 경로가 유지되지 않고 원래대로 돌아와 버립니다. 따라서 cd 를 이용해서 경로 작업을 할 때에는 % 를 사용해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpCCroKgWj9n",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "!ls\n",
        "%cd /content/gdrive/\"My Drive\"/data/\n",
        "\n",
        "# 혹시 이전에 스크립트릴 실행했을 수 있으니, 다시 실행시키려면 그 전에 미리 잘 지워줍시다.\n",
        "!rm -r helmetclassification \n",
        "\n",
        "# 경로들을 만들어 줍시다.\n",
        "!mkdir helmetclassification\n",
        "!mkdir helmetclassification/helmet\n",
        "!mkdir helmetclassification/non_helmet\n",
        "\n",
        "# 압축 해제!\n",
        "!unzip helmet_crop.zip -d /content/gdrive/\"My Drive\"/data/helmetclassification/helmet\n",
        "!unzip nonhelmet_crop.zip -d /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet\n",
        "!unzip nonhelmet2.zip -d /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi1C99JBgves",
        "colab_type": "text"
      },
      "source": [
        "## Hyper Parameters\n",
        "- 하이퍼파라미터들을 위에 모아서 정의해두는 습관\n",
        "- google colab 에서는 아까 언급했던 % magic 을 이용해서 tensorboard 를 쉽게 사용할 수 있도록 만들어 두었습니다. (그런데 잘 돌아가지는 않음)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsqrbpKteFLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKf4BLAFbcz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/\n",
        "\n",
        "# 데이터가 존재하는 경로 ( /content/gdrive/\"My Drive\"/data/helmetclassification ) 를 data_dir 변수에 저장합니다.\n",
        "data_dir = os.path.join(os.getcwd(), 'helmetclassification')\n",
        "print(data_dir)\n",
        "\n",
        "# input 이미지의 크기는 기본적으로 224 by 224 by 3 으로 상정합니다. 채널은 RGB 이므로, 3 입니다.\n",
        "# 저희의 경우, input image 의 해상도가 높으면 안 될 수 있기 때문에, size 를 약간 줄이도록 하겠습니다. \n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "IMG_CHANNEL = 3\n",
        "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL)\n",
        "\n",
        "# 연산 처리 단위 (배치) 는 이미지 16장, 그리고 Learning Rate, optimizer, 에폭 등을 설정합니다.\n",
        "# *참고* : Optimizer 에서 SGD 는 최근 잘 사용하지 않지만, 안정적인 수렴을 위해 특정 경우에 사용합니다. \n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE_SGD = 0.001\n",
        "LEARNING_RATE_ADAM = 0.0001\n",
        "TRAINING_OPTIMIZER_SGD  = tf.keras.optimizers.SGD(learning_rate=LEARNING_RATE_SGD, momentum=0.0)\n",
        "TRAINING_OPTIMIZER_ADAM = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE_ADAM)\n",
        "EPOCHS = 30\n",
        "\n",
        "# 우리는 h5 file 을 tflite 파일로 전환할 것입니다. 이름을 미리 정해 둡시다.\n",
        "SAVED_KERAS_MODEL_NAME = 'helmet_classification_model.h5'\n",
        "\n",
        "# 우리는 잠시 후에 라벨 파일을 만들어낼 것인데, 라벨 파일의 이름을 미리 정의해 둡시다.\n",
        "LABEL_FILE_NAME = 'ishelmetlabel.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GemJq1CujkU9",
        "colab_type": "text"
      },
      "source": [
        "## Generator\n",
        "- python 에는 '제네레이터' 라는 것이 존재합니다.\n",
        "- 그 때 그 때, 상황에 맞는 데이터를 만들어 주는 역할을 수행합니다.\n",
        "- keras 에서는, 이를 이용하여, 우리가 가지고 있는 image data 들을 정갈하게 정리해서 하나씩 하나씩 필요에 맞게 넘겨 주는 함수를 만들어 두었습니다. \n",
        "\n",
        "<br>\n",
        "\n",
        "### ImageDataGenerator : Data Augmentation\n",
        "- Data Augmentation 은 말 그대로 데이터를 증폭시켜주는 역할을 합니다.\n",
        "- 고양이 사진이 있을 때, 고양이 머리만 있어도 고양이이고, 몸통만 있어도 고양이이며, 형광등 아래의 고양이도 고양이고, 백열등 아래의 고양이도 고양이입니다.\n",
        "- 우리가 가지고 있는 이미지를 인위적으로 변형한 뒤에도, 올바르게 추론할 수 있도록 이미지 데이터를 다양한 방법으로 변형시켜줄 수 있도록 돕는 함수가 Keras 의 ImageDataGenerator 입니다.\n",
        "- Train 할 때는 이미지를 변형해서 forward-pass 시켜주지만, test 를 할 때에는 이미지를 변형해서 네트워크를 통과시키면 안 되겠지요.\n",
        "- 다만, Train 이나 Test 시에는 Network 의 사양에 맞추어서 0~1 의 범위로 input 을 정규화 시켜 주어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvEQ8ZedbJLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    rescale=1./255,\n",
        "    dtype='float',\n",
        "    fill_mode=\"nearest\",\n",
        "    horizontal_flip=True,\n",
        "    channel_shift_range=0.1, \n",
        "    rotation_range=20,\n",
        "    brightness_range=(-0.3, 0.3)\n",
        "    )\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    dtype='float',\n",
        "    validation_split=0.8\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSX6i95pgq12",
        "colab_type": "text"
      },
      "source": [
        "## Train-Valid(Test-Validation) Data Split\n",
        "\n",
        "- keras 는 image classification 과 같은 간단한 문제들을 쉽게 해결할 수 있도록 돕기 위해 ```flow_from_directory``` 와 같은 함수를 제공합니다.\n",
        "- 위에서 만들었던 ImageDataGenerator() 을 거친 객체들을 ```flow_from_directory``` 에 대입하여 간단하게 클래스별로 학습을 시킬 수 있습니다.\n",
        "- 이때 Keras 는 미리 데이터를 '/train' 폴더와 '/test' 폴더로 나누어 놓기를 요구합니다.\n",
        "- 하지만 우리는 train data 와 test data 를 나누어두지 않았습니다. 이 경우에도, Keras 는 우리의 작업을 도와줄 수 있는 함수를 제공하지만, 해당 함수를 사용하면, Data Augmentation 을 정상적으로 수행할 수 없습니다.\n",
        "- 따라서, 우리가 직접 모은 데이터들을 train 과 test 폴더로 분리해서 담아 주는 스크립트를 작성해 봅시다.\n",
        "\n",
        "*Data Augmentation 과 train_test split 사이의 문제 : 궁금하신 분들은 참고 : [관련 이슈](https://stackoverflow.com/questions/53037510/can-flow-from-directory-get-train-and-validation-data-from-the-same-directory-in)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndiMiZvThUl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 현재 디렉터리 이동\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "\n",
        "# /content/gdrive/\"My Drive\"/data/helmetclassification/ 에 train 과 test 폴더를 만들어 줍니다.\n",
        "!mkdir train\n",
        "!mkdir train/helmet\n",
        "!mkdir train/non_helmet\n",
        "!mkdir test\n",
        "!mkdir test/helmet\n",
        "!mkdir test/non_helmet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKEWWrOJZ7mW",
        "colab_type": "text"
      },
      "source": [
        "### Wearing Helmet Data\n",
        "- test 데이터 랜덤하게 뽑아내기\n",
        "- 뽑은 데이터 test 폴더로 옮겨주기\n",
        "- 나머지 데이터를 train 폴더로 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzOGLIFjkh8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /content/gdrive/\"My Drive\"/data/helmetclassification/helmet 경로부터 작업해 줍시다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/helmet\n",
        "\n",
        "helmet_data_directory = os.getcwd()\n",
        "file_list = os.listdir(helmet_data_directory)\n",
        "print('Count of file :', len(file_list))\n",
        "\n",
        "import random\n",
        "sampled_helmet_file_list = random.sample(file_list, int(len(file_list) * 0.4))\n",
        "print('Count of sampled file :', len(sampled_helmet_file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeE6WeZnmDhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이제 sample 된 데이터를 /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet 으로 옮겨 줄 차례입니다.\n",
        "import shutil\n",
        "target_dir = os.path.join(os.path.join(data_dir, 'test'), 'helmet')\n",
        "for f in sampled_helmet_file_list :\n",
        "  current_file = os.path.join(helmet_data_directory, f)\n",
        "  shutil.move(current_file, os.path.join(target_dir, f))\n",
        "  print(current_file,'\\t->\\t',os.path.join(target_dir, f))\n",
        "\n",
        "# 이제 test 데이터를 모두 옮겼으니, train 데이터도 모두 옮겨 줍시다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "!mv helmet/ train/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px_BlwjVZ_Y1",
        "colab_type": "text"
      },
      "source": [
        "### Not Wearing Helmet Data\n",
        "- test 데이터 랜덤하게 뽑아내기\n",
        "- 뽑은 데이터 test 폴더로 옮겨주기\n",
        "- 나머지 데이터를 train 폴더로 옮기기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FYuZtyak1fA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet 경로를 작업할 차례입니다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet\n",
        "\n",
        "# 해당 경로는, 다양한 경로로부터 사람의 이미지를 취득했기에, 이를 모두 모아주는 작업이 필요합니다.\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print(file_list)\n",
        "\n",
        "# 내부에 MACOS 용 파일과 자잘한 더미 파일이 존재하니 이를 제거해 줍니다.\n",
        "!rm -r __MACOSX\n",
        "!rm ./pedestrian/.DS_Store\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loZJArDddq1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/non_helmet\n",
        "\n",
        "file_list = []\n",
        "for (root, dirs, files) in os.walk(os.getcwd()):\n",
        "  print(\"root : \" + root)\n",
        "  if len(files) > 0:\n",
        "    for file_name in files:\n",
        "      if file_name[-3:] in ['jpg', 'png'] :\n",
        "        file_full_path = os.path.join(root, file_name)\n",
        "        print('append to file_list : ', file_full_path)\n",
        "        file_list.append(file_full_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KokVJakP_5jS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "sampled_nonhelmet_file_list = random.sample(file_list, int(len(file_list) * 0.4))\n",
        "print('Count of sampled file :', len(sampled_nonhelmet_file_list), 'out of', len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPSTmG5HlQgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이제 sample 된 데이터를 /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet 으로 옮겨 줄 차례입니다.\n",
        "import shutil\n",
        "target_dir = os.path.join(os.path.join(data_dir, 'test'), 'non_helmet')\n",
        "for cnt, f in enumerate(sampled_nonhelmet_file_list) :\n",
        "  # 새로운 임시 이름 (cnt) + 확장자 (.xxx) 로 새로운 이름을 부여\n",
        "  postfix = str(cnt) + f[-4:] \n",
        "  shutil.move(f, os.path.join(target_dir, postfix))\n",
        "  print('[test data]', f,'\\t->\\t',os.path.join(target_dir, postfix))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehT0SCzSfRBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test 데이터를 모두 옮겼으니, train 데이터도 모두 옮겨 줍시다.\n",
        "cnt = 0\n",
        "target_dir = os.path.join(os.path.join(data_dir, 'train'), 'non_helmet')\n",
        "for f in file_list:\n",
        "  if os.path.isfile(f):\n",
        "    postfix = str(cnt) + f[-4:]\n",
        "    shutil.move(f, os.path.join(target_dir, postfix))\n",
        "    print('[train data]', f,'\\t->\\t',os.path.join(target_dir, postfix))\n",
        "    cnt += 1\n",
        "\n",
        "# 원래 존재하던 폴더를 지워 버립시다.\n",
        "# %cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "# !rm -r non_helmet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJrWWEP9E9pY",
        "colab_type": "text"
      },
      "source": [
        "### Finally Check data\n",
        "- 데이터셋을 확인했을 때, 이미지의 크기가 너무 작아서, 확대했을 때 너무 깨져서 정상적인 학습을 방해하는 경우가 존재할 수 있습니다.\n",
        "- 그 이유는, 우리가 직접 object detection dataset 을 classification dataset 으로 변경한 helmet dataset 은, 얼굴을 잘라서 모두 다른 데이터로 사용했기 때문에 사이즈가 작은 경우가 non helmet dataset 보다 월등히 많습니다.\n",
        "- 어차피 helmet dataset 의 개수가 훨씬 많으니, 이를 조정하는 과정을 거쳐 보도록 합시다.\n",
        "- 이미지를 전부 읽어들여 크기를 재야 하는 작업이라, 꽤 많은 시간이 걸립니다. \n",
        "- 이 과정을 처음 data 를 만들때부터 하지 않았던 이유는, 누군가는 저해상도 image 가 유의미한 자료라고 생각하고 학습 시 사용할 수 있기 때문입니다.\n",
        "- 나의 모델을 만들고자 할 때, 전처리는 항상 번거롭고 고된 작업입니다.\n",
        "- 노트북의 런타임이 실행된 이후, 처음 셀이 실행된다면 데이터 캐싱에 오랜 시간이 걸리기 때문에 많은 시간이 소요될 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWorByUuFGmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미지의 size 를 재기 위해, PIL 을 import 합니다\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIyZjDrI0NzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/train/helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "remove_candidate_helmet_training_file_list = []\n",
        "cnt = 0\n",
        "for i, img_name in enumerate(file_list):\n",
        "  print(i, '/', len(file_list))\n",
        "  img = Image.open(img_name)\n",
        "  if img.size[0] * img.size[1] < IMG_WIDTH * 0.3  * IMG_WIDTH * 0.3 : # 이미지의 해상도가 input 해상도의 1/9 수준이라면. \n",
        "                                                                      # 1/9 로 잡은 이유는, nonhelmet data 의 개수와 비슷하게 맞추기 위함입니다.\n",
        "    cnt+=1\n",
        "    remove_candidate_helmet_training_file_list.append(img_name)\n",
        "print(\"low resolution ratio : \", cnt, '/', len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIaIVJIx0Pm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "remove_candidate_helmet_testing_file_list = []\n",
        "cnt = 0\n",
        "for i, img_name in enumerate(file_list):\n",
        "  print(i, '/', len(file_list))\n",
        "  img = Image.open(img_name)\n",
        "  if img.size[0] * img.size[1] < IMG_WIDTH * 0.3  * IMG_WIDTH * 0.3 :\n",
        "    cnt+=1\n",
        "    remove_candidate_helmet_testing_file_list.append(img_name)    \n",
        "print(\"low resolution ratio : \", cnt, '/', len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nMEpiGJ2urf",
        "colab_type": "text"
      },
      "source": [
        "이제 선택된 사진들을 지워보도록 해요\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1HWkuIl2uEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/train/helmet/\n",
        "for img_name in remove_candidate_helmet_training_file_list :\n",
        "  os.remove(img_name)\n",
        "\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet/\n",
        "for img_name in remove_candidate_helmet_testing_file_list :\n",
        "  os.remove(img_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWuBA7K_kkVN",
        "colab_type": "text"
      },
      "source": [
        "### Check Directory\n",
        "- 잘 정리되었나 확인해 봅시다\n",
        "- train, test 폴더만 남아 있어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRWf-EcZkfXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzxUIPIFJ-t2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helmet\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/train/helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('count of train helmet file :', len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM8AKosdJ_Qv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helmet\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/test/helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('count of test helmet file :', len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dj-dK-hGJ_eH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# non_helmet\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/train/non_helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('Count of train non_helmet file :', len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er_0CECKKGGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# non_helmet\n",
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification/test/non_helmet/\n",
        "file_list = os.listdir(os.getcwd())\n",
        "print('Count of test non_helmet file :', len(file_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRCJMSXjqaZW",
        "colab_type": "text"
      },
      "source": [
        "## Data Generator Flow From Directory\n",
        "- Keras 는 Directory 이름과 해당 폴더로부터 알아서 클래스를 구분해주고, 쉽게 training 시킬 수 있도록 API 를 제공합니다.\n",
        "- train_generator : generator 로써, next() 수행 시 하나의 tensor 를 만들어냅니다.\n",
        "  - 한 번에 만들어내는 tensor 은 (image tensor, label tensor) 이고, 그 shape 은 (batch_size, 224, 224, 3)  (batch_size, 2 - 클래스가 2개이므로) 입니다.\n",
        "- val_generator : generator 로써, 이하동문.\n",
        "  - 한 번에 만들어내는 tensor 은 (image tensor, label tensor) 이고, 그 shape 은 (1, 224, 224, 3)  (1, 2) 입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZD0OId0gqQW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Training data generator during training session')\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir+'/train',\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "print('\\nValidation data generator during training session')\n",
        "val_generator = test_datagen.flow_from_directory(\n",
        "    data_dir+'/test',\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset=\"training\"\n",
        "    )\n",
        "\n",
        "print('\\nTest data generator when the end of training session')\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    data_dir+'/test',\n",
        "    color_mode=\"rgb\",\n",
        "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "    batch_size=1,\n",
        "    subset=\"validation\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x0en3V-blmN",
        "colab_type": "text"
      },
      "source": [
        "### Label 생성기\n",
        "- 우리가 데이터들을 (non_helmet, helmet) 클래스별로 train, test 로 나누고 깔끔하게 데이터를 전부 모아 두었으므로, 해당 폴더 이름으로부터 label 파일을 만들 수 있습니다.\n",
        "- label 파일이란, 모델이 추론한 결과가 어떤 클래스를 의미하는지 정보를 담고 있는 그냥 이름표 파일이라고 생각하면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cmVOrdEbiq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 디렉토리 이름을 라벨로 바로 써버리는 소스코드입니다.\n",
        "%cd /content/gdrive/\"My Drive\"/data/\n",
        "\n",
        "print(train_generator.class_indices) # type dictionary\n",
        "print(len(train_generator.class_indices))\n",
        "class_cnt = len(train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "with open('{}'.format(LABEL_FILE_NAME), 'w') as f:\n",
        "  f.write(labels)\n",
        "\n",
        "!cat {LABEL_FILE_NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu9c78aFjwml",
        "colab_type": "text"
      },
      "source": [
        "# Model For training\n",
        "- 이제 모델을 만들고, 훈련을 시켜 보도록 합시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJvbokNJS4zr",
        "colab_type": "text"
      },
      "source": [
        "### 선택지1 : MobileNet V2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8eciMIMdhgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the base model from the pre-trained MobileNet V2\n",
        "full_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=True,\n",
        "                                               classes=2,\n",
        "                                               weights=None,\n",
        "                                               # If, instead, you want to reuse the pretrained models (e.g.: by setting weights='imagenet' in the definition of MobileNetV2), then you should use the specific preprocessing in\n",
        "                                               )\n",
        "full_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYdqDWwSd2Be",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_model.compile(optimizer=TRAINING_OPTIMIZER_ADAM, \n",
        "                  loss='categorical_crossentropy', \n",
        "                  metrics=['accuracy'])\n",
        "full_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Km22RN4C6M1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dense_layer = full_model.layers[-1].get_weights()[0]\n",
        "gap_layer = full_model.layers[-2].output\n",
        "final_conv_layer = full_model.layers[-3].output\n",
        "print(type(dense_layer), type(gap_layer), type(final_conv_layer))\n",
        "print('dense layer W shape : ', dense_layer.shape)\n",
        "print('GAP layer output tensor shape : ', gap_layer.shape)\n",
        "print('final convolution layer output tensor shape : ', final_conv_layer.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpgtpT6Tj0rl",
        "colab_type": "text"
      },
      "source": [
        "## Train\n",
        "- 모델을 다 만들었으니 이제 훈련을 시킬 차례입니다.\n",
        "- 그런데 훈련을 시작하게 되면, 개입이 불가능해집니다.\n",
        "- 따라서 특정 타이밍(예를 들어, 1에폭마다) 적절히 호출되는 콜백 함수를 미리 등록시켜 두고, 훈련을 시작하는 것이 바람직합니다.\n",
        "  - 중간중간 모델의 가중치를 세이브하는 기능\n",
        "  - 텐서보드로 로그를 전송하는 기능\n",
        "- 일반적으로 이 두 가지 기능을 callback 으로 등록시켜 두곤 합니다.\n",
        "- keras_model.fit_generator() 함수가 호출되면 Training 이 시작됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqyc2eFHMKOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "# 저장할 로그 파일의 이름을 준비합니다. 로그 파일이 존재해야 tensorboard 를 불러올 수 있습니다.\n",
        "log_dir = os.path.join(os.getcwd(), os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,     # 저장할 로그파일의 이름을 지정합니다.\n",
        "                                                      histogram_freq=1,    # 가중치나 이런 것들을 visualization 하는 histogram 을 그리는 작업을 1 epoch 마다 합니다. \n",
        "                                                      update_freq='epoch'  # 1에폭마다 Tensorboard 를 갱신합니다.\n",
        "                                                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwBXZDzvMVbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification\n",
        "%tensorboard --logdir {\"logs\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcEAmlYwuh7v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# checkpoint 를 저장합니다. checkpoint 파일은 cp-<저장하는 시간>-<에폭에 해당하는 네자리수>.ckpt 라는 이름으로 지정합니다.\n",
        "# 본인이 알아보기 편한 형식으로 지정하면 되지만, checkpoint 별로 이게 몇 에폭을 학습한 결과인지, 언제 저장한 결과인지 정도는 저장이 되어 있어야 하기 때문에, 저는 이런 형식으로 지정했습니다.\n",
        "import datetime\n",
        "# 우리는 checkpoint 를 설정해서, 각 epoch 마다 가중치를 저장할 것입니다.\n",
        "CKPT_DIR = os.path.join(data_dir, 'checkpoint')\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    os.path.join(CKPT_DIR, \"cp-\" + str(datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")) + \"-{epoch:04d}-kerasbuiltin.ckpt\"), monitor='val_loss', verbose=0, save_best_only=False,\n",
        "    save_weights_only=False, mode='auto', save_freq='epoch', options=None,\n",
        ")\n",
        "\n",
        "# 최근 저장했던 checkpoint 가 존재한다면, 저장되어 있는 checkpoint 들 중에서 최근의 checkpoint 를 불러와야 하겠지요.\n",
        "'''\n",
        "final_checkpoint_name = \"cp-20200904-1635-0015.ckpt\"\n",
        "full_model.load_weights(os.path.join(CKPT_DIR, final_checkpoint_name))\n",
        "EPOCHS = 1 # 이어서 학습하는 것이라면 epoch 를 조절해 주어야겠지요.\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZf5lLymd73I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습 시작. 변수 history 는 학습을 마친 뒤 학습중 있었던 일들을 볼 수 있도록 keras 에서 제공하는 객체입니다.\n",
        "history = full_model.fit_generator(train_generator, \n",
        "                                   epochs=EPOCHS, \n",
        "                                   validation_data=val_generator,\n",
        "                                   callbacks=[\n",
        "                                              tensorboard_callback,\n",
        "                                              ],\n",
        "                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYSL68SZj3q6",
        "colab_type": "text"
      },
      "source": [
        "## Estimate\n",
        "- train 의 과정과 결과를 보는 방법은, tensorboard 를 활용하는 방법도 있고, history 객체를 이용하는 방법도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDgJ0p8veNOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# history 객체 이용\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(19, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rUGp3sTjIBS",
        "colab_type": "text"
      },
      "source": [
        "### Estimate with Testset\n",
        "- 학습 과정에서의 변화를 관찰했다면, 이제 우리가 아직 사용하지 않은 test set 을 활용해서 학습 결과를 관찰해 보도록 합시다.\n",
        "- 제네레이터에서 제공되는 샘플로 평가할 때는 evaluate_generator 함수를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBgB97fPjHTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores  = tf.keras.Model.evaluate_generator( \n",
        "  full_model,\n",
        "  test_generator,   # test_generator 은 batch size 가 1 입니다.\n",
        "  steps = 500,      # batch_size 가 1 인 test_generator 을 사용하므로, 500장으로 평가합니다.\n",
        "  workers = 4,\n",
        "  callbacks = None\n",
        ")\n",
        "print(scores, \" % Accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkemHKX_jCde",
        "colab_type": "text"
      },
      "source": [
        "# Save Entire Model\n",
        "- keras 는 다시 keras 를 이용해서 쉽게 모델을 불러올 수 있도록 저장하는 API 를 가지고 있습니다.\n",
        "- 저장합시다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEfYMSrYjCBq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/gdrive/\"My Drive\"/data/helmetclassification\n",
        "full_model.save(SAVED_KERAS_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9hFqjeBmN5N",
        "colab_type": "text"
      },
      "source": [
        "# Next Time (part2)\n",
        "수고했습니다! Part 2 에서는 다음과 같은 내용을 진행해 보도록 합시다.\n",
        "- keras 내장 모델인 mobilenet v2 를 불러오지 말고, 직접 mobilenet v2 를 구현해 봅시다.\n",
        "- 구현된 모델을 조금 수정하면서, Class Activation Map* 을 한번 visualization 해 봅시다.\n",
        "\n",
        "*Class Activation Map 이란, Helmet 클래스로 판단하는 데 어떤 부분을 가장 주목해서 보았는지와 같이, 어떤 클래스로 판단하는 것의 근거를 Visualization 한 이미지를 의미합니다. "
      ]
    }
  ]
}